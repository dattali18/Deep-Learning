{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"provenance":[{"file_id":"1W3oqIQ3-Tp1Jyh1kwt1sg1wuOvCssIaW","timestamp":1719388123620},{"file_id":"1wCNr4kUA_ZAWlVfxEmRL7ICyScU11Vn8","timestamp":1719387980060},{"file_id":"1uUuUvlJQiTA2Rcohpb1ycOJkAUt65O2j","timestamp":1719387805169},{"file_id":"1M6Xb5slip6yCt_jESXc9aqE92qW482BU","timestamp":1719387010751},{"file_id":"1d4v390FsxZLuVc0tpJXExU3d21f94VzV","timestamp":1719385892469},{"file_id":"1aJWC1eFfj-fHOql_IpJ50k5hKZNAp0y1","timestamp":1618855088947}],"gpuType":"T4"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bIxsHxttP2k5"},"source":["## Building a CNN to classify images in the CIFAR-10 Dataset\n","\n","We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n","\n","The 10 classes are:\n","\n","<ol start=\"0\">\n","<li> airplane\n","<li>  automobile\n","<li> bird\n","<li>  cat\n","<li> deer\n","<li> dog\n","<li>  frog\n","<li>  horse\n","<li>  ship\n","<li>  truck\n","</ol>\n","\n","For details about CIFAR-10 see:\n","https://www.cs.toronto.edu/~kriz/cifar.html\n","\n","For a compilation of published performance results on CIFAR 10, see:\n","http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n","\n","---\n","\n","### Building Convolutional Neural Nets\n","\n","In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance.\n","\n","Much of this code is from Intel's course at: https://software.intel.com/content/dam/develop/public/us/en/downloads/intel-dl101-class6.zip, but I added some tweaks of my own ;)"]},{"cell_type":"code","metadata":{"id":"eQC8thNfP2k_"},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from tensorflow.keras import layers\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfQekVzZP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388347222,"user_tz":-180,"elapsed":12096,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"92b62cc7-cacd-4e68-a3ae-646733c11c2c"},"source":["# The data, shuffled and split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 4s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"]}]},{"cell_type":"code","metadata":{"id":"Nc4W3uKIP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388347223,"user_tz":-180,"elapsed":23,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"e207b3f9-5541-4f8e-8df4-b4eb20d49a5e"},"source":["## Each image is a 32 x 32 x 3 numpy array\n","x_train[444].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 32, 3)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"P2OIsQqOnKAN"},"source":["Notice that this time the pictures have color (RGB color with 3 channels)."]},{"cell_type":"code","metadata":{"id":"ePODxy5uP2lA","colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"status":"ok","timestamp":1719388347942,"user_tz":-180,"elapsed":730,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"1bb93725-f9a8-4aae-a75b-20a36be7ec0e"},"source":["## Let's look at one of the images\n","\n","print(y_train[442])\n","plt.imshow(x_train[442]);"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"czYvqoRAP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388347943,"user_tz":-180,"elapsed":163,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"4807b70f-4ba6-4e0a-c378-991daac35dfa"},"source":["#On my local machine I had to write:\n","#from keras.utils.np_utils import to_categorical'''\n","from keras.src.utils.np_utils import to_categorical\n","num_classes = 10\n","print(y_train[442])\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8]\n"]}]},{"cell_type":"code","source":["print(y_train[442])"],"metadata":{"id":"svjNH-7wrL1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388347943,"user_tz":-180,"elapsed":159,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"0c3d8ec9-3e0b-4ce6-9fdc-e1300aa7db66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"wSh-NIvhP2lB"},"source":["# As before, let's make everything float and scale\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8eluWt3P2lB"},"source":["## Keras Layers for CNNs\n","- Previously we built Neural Networks using primarily the Dense, Activation and Dropout Layers.\n","\n","- Here we will describe how to use some of the CNN-specific layers provided by Keras\n","\n","### Conv2D\n","\n","```python\n","keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n","```\n","\n","A few parameters explained:\n","- `filters`: the number of filter used per location.  In other words, the depth of the output.\n","- `kernel_size`: an (x,y) tuple giving the height and width of the kernel to be used\n","- `strides`: and (x,y) tuple giving the stride in each dimension.  Default is `(1,1)`\n","- `padding`: With \"SAME\" padding, if you use a stride of 1, the layer's outputs will have the same spatial dimensions as its inputs. (otherwise you will loose size due to the filter)\n","- `input_shape`: required only for the first layer\n","\n","Note, the size of the output will be determined by the kernel_size, strides\n","\n","### MaxPooling2D\n","`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n","\n","- `pool_size`: the (x,y) size of the grid to be pooled.\n","- `strides`: Assumed to be the `pool_size` unless otherwise specified\n","\n","### Flatten\n","Turns its input into a one-dimensional vector (per instance).  Usually used when transitioning between convolutional layers and fully connected layers.\n","\n","---\n","\n","## First CNN\n","Below we will build our first CNN.  For demonstration purposes (so that it will train quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output.  After a MaxPooling layer, we flatten, and then have a single fully connected layer before our final classification layer."]},{"cell_type":"code","metadata":{"id":"xd7SfmLsP2lC"},"source":["# Let's build a CNN using Keras' Sequential capabilities\n","\n","model_1 = keras.Sequential(\n","    [\n","        keras.Input(shape=(32, 32, 3)),\n","        keras.layers.Conv2D(32, kernel_size=(5, 5), strides = (2,2), padding='same', activation=\"relu\"),\n","        keras.layers.Conv2D(32, kernel_size=(5, 5), strides = (2,2), padding='same', activation=\"relu\"),\n","        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","        #keras.layers.Dropout(0.25),\n","        keras.layers.Flatten(),\n","        keras.layers.Dense((512), activation=\"relu\"),\n","        keras.layers.Dropout(0.5),\n","        keras.layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_1.summary()"],"metadata":{"id":"a1ziWTfZiPRq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388349612,"user_tz":-180,"elapsed":370,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"0441e27d-aee1-4436-d661-abb120c8e27b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 16, 16, 32)        2432      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 8, 8, 32)          25632     \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 4, 4, 32)          0         \n"," D)                                                              \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               262656    \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 295850 (1.13 MB)\n","Trainable params: 295850 (1.13 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"hsjjm7nUP2lC"},"source":["We still have 181K parameters, even though this is a \"small\" model.\n","Note that the formula:\n","\n","output_width=(input_width-kernel_width)/stride+1\n","holds.  For example in the first layer, input_width=32, kernel_width=5 and stride = 2.  So:\n","output_width=(32-5)/2 + 1 = 14 WITHOUT Padding.  But here padding = same, so output = 32/2 (due to stride)= 16. Without stride = 2 it would have been 32 had padding = same.\n","\n","In the second layer:\n","output_width=((16-5)/2)+1 = 6\n","\n","weights=(previous_layer_num_features x kernel_width x kernel_height + b) x filters\n","\n","For example, in the first layer = (3X5X5+1)X32=2432"]},{"cell_type":"code","metadata":{"id":"TQJhSyUmP2lD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388494462,"user_tz":-180,"elapsed":144859,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"feee9a76-12ec-4b4f-b7b9-e7ccbb7c9080"},"source":["batch_size = 32\n","num_epochs = 10\n","\n","# initiate Adam optimizer like in the first example\n","model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","# initiate RMSprop optimizer\n","#opt = keras.optimizers.RMSprop(lr=0.0005, decay=0.00001)\n","\n","# Let's train the model using RMSprop\n","#model_1.compile(loss='categorical_crossentropy',\n","#              optimizer=opt,\n","#              metrics=['accuracy'])\n","\n","model_1.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=num_epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1563/1563 [==============================] - 17s 8ms/step - loss: 1.5618 - accuracy: 0.4310 - val_loss: 1.3373 - val_accuracy: 0.5153\n","Epoch 2/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.2693 - accuracy: 0.5471 - val_loss: 1.1729 - val_accuracy: 0.5851\n","Epoch 3/10\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.1508 - accuracy: 0.5912 - val_loss: 1.1143 - val_accuracy: 0.6074\n","Epoch 4/10\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.0725 - accuracy: 0.6240 - val_loss: 1.0669 - val_accuracy: 0.6252\n","Epoch 5/10\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.0094 - accuracy: 0.6441 - val_loss: 1.0183 - val_accuracy: 0.6419\n","Epoch 6/10\n","1563/1563 [==============================] - 8s 5ms/step - loss: 0.9552 - accuracy: 0.6624 - val_loss: 1.0144 - val_accuracy: 0.6463\n","Epoch 7/10\n","1563/1563 [==============================] - 9s 5ms/step - loss: 0.9131 - accuracy: 0.6759 - val_loss: 1.0025 - val_accuracy: 0.6508\n","Epoch 8/10\n","1563/1563 [==============================] - 7s 4ms/step - loss: 0.8751 - accuracy: 0.6902 - val_loss: 0.9608 - val_accuracy: 0.6650\n","Epoch 9/10\n","1563/1563 [==============================] - 8s 5ms/step - loss: 0.8400 - accuracy: 0.7043 - val_loss: 0.9942 - val_accuracy: 0.6589\n","Epoch 10/10\n","1563/1563 [==============================] - 7s 5ms/step - loss: 0.8033 - accuracy: 0.7139 - val_loss: 0.9692 - val_accuracy: 0.6701\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a96beadab30>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"dOy-IQMuU4l0"},"source":["## Evaluate the trained model"]},{"cell_type":"code","metadata":{"id":"3Z8y3b2GU4l1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719388495199,"user_tz":-180,"elapsed":757,"user":{"displayName":"Daniel Attali","userId":"07251378521943271019"}},"outputId":"b6ab3489-2eb9-44bc-9112-f2f4fe04a678"},"source":["score = model_1.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.9691784977912903\n","Test accuracy: 0.6700999736785889\n"]}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"jmOeUBmvP2lE"},"source":["### Exercise\n","There are many things we can change in CNNs:\n","1. The batch size\n","2. The parameters within a specific CNN layer such as if padding is used, the size (kernel size) and number of filters used, and stride size\n","3. The Dropout rate (if any) that is used\n","4. The CNN architecture including the number of layers and if and when to use MaxPool (AvgPool usually isn't used today).\n","5. The optimizer used (and the learning rate in the optimizer)\n","6. In theory which activation function, but in CNN's Relu is almost always used except for the last layer which is Softmax (which activation function is Softmax???)\n","\n","Questions:\n","\n","A. Build model_2_1, model_2_2, model_2_3 which checks the performance of batch sizes of 4, 128 and 1024.  Which one works best after 10 epochs?  Which one runs the fastest?\n","\n","B. Build model_3 which adds padding to all layers. Does that improve performance?\n","\n","C. Build model_4 which uses the same architecture from the MNIST network. Does that work better?\n","\n","D. Build model_5 which adds to the structure of model_1-- either by adding more convolution layers or Maxpool layers.   Intel suggests trying the architecture:\n","\n","Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n","\n","instead of:\n","\n","Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n","\n","If you do this, you will likely need to lower the stride to 1 as otherwise the layers are not big enough in this dataset!\n","\n","Please run the network that worked the best for more than 10 epochs and see how good you get!\n","\n","Hint:  Feel free to work on different colab notebooks in parallel (Google doesn't care until around 5 at the same time) and / or run the code on your computer and then paste it back to Colab when you are done (the code works faster on my computer than in Colab but everyone's computer is different).\n","\n","Your grade is based on the following:\n","\n","80 points for correctly doing all questions and documenting your solution including the answers to the my questions.\n","\n","5 points for breaking 65% accuracy in your best model\n","\n","10 points for breaking 70% accuracy in your best model\n","\n","3 points for breaking 72% accuracy in your best model\n","\n","2 points for breaking 75% accuracy in your best model"]}]}